{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3552e4-524d-44e4-8d1d-061fd663df09",
   "metadata": {},
   "source": [
    "## Since the pre-trained weights may not perfectly match mmaction, you need to modify the key of the pre-trained weights in most cases. \n",
    "- The following takes VideoMAE Base K710 as an example for correction. Other pre-trainings are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90564cf-6efa-4137-90b8-ed7772bb501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the Output\n",
    "import torch\n",
    "dicts = torch.load('autodl-tmp/pretrained/vit_b_hybrid_pt_800e.pth')['model']\n",
    "for k,v in dicts.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e4c98-f6b8-44e6-afe8-2feb41167b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify\n",
    "# mae_pretrained\n",
    "import torch\n",
    "dicts = torch.load('autodl-tmp/pretrained/vit_b_hybrid_pt_800e_k710_ft.pth')['model']\n",
    "new_dicts = {}\n",
    "for k,v in dicts.items():\n",
    "    if 'encoder.' in k:\n",
    "        k = k.replace('encoder', 'backbone')\n",
    "        if 'patch_embed.proj' in k:\n",
    "            k = k.replace('proj', 'projection')\n",
    "        elif 'fc1' in k:\n",
    "            k = k.replace('fc1', 'layers.0.0')\n",
    "        elif 'fc2' in k:\n",
    "            k = k.replace('fc2', 'layers.1')\n",
    "        elif 'backbone.norm' in k:\n",
    "            k = k.replace('norm', 'fc_norm')\n",
    "        new_dicts[k] = v\n",
    "    else:\n",
    "        continue\n",
    "torch.save(new_dicts, 'autodl-tmp/pretrained/vit_b_hybrid_pt_800e_k710_ft_mmv.pth')\n",
    "for k,v in new_dicts.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4822ddf-91e5-4b85-b3b6-cf1aecba6781",
   "metadata": {},
   "source": [
    "## The weight modification of the dual-stream network is quite special, and the operation is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddeeb27-53f4-4b09-b254-94063c1b73db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dicts = torch.load('autodl-tmp/pretrained/vit_l_hybrid_pt_800e_k700_ft.pth')['module']\n",
    "del dicts['head.weight'], dicts['head.bias']\n",
    "new_dicts = {}\n",
    "for k,v in dicts.items():\n",
    "    k = 'backbone.' + k\n",
    "    if 'patch_embed.proj' in k:\n",
    "        new_dicts[k.replace('proj', 'projection')] = v\n",
    "    elif 'fc1' in k:\n",
    "        new_dicts[k.replace('fc1', 'layers.0.0')] = v\n",
    "    elif 'fc2' in k:\n",
    "        new_dicts[k.replace('fc2', 'layers.1')] = v\n",
    "    elif 'backbone.norm' in k:\n",
    "        new_dicts[k.replace('norm', 'fc_norm')] = v\n",
    "    else:\n",
    "        new_dicts[k] = v\n",
    "torch.save(new_dicts, 'autodl-tmp/pretrained/vit_l_hybrid_pt_800e_k700_ft_mmv.pth')\n",
    "for k,v in new_dicts.items():\n",
    "    print(k, v.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
